# Practicum Projects

## About
#### This repostitory containts 15 different projects focused on data storytelling, statistical analysis, data parsing, and machine learning, for the Data Science Professional Training Certificate Program by Practicum. 

## Table of contents:

| **Name of Project**  | **Description of Project**  | **Tools/concepts used** | **Link to Project** | 
| :------------ |:---------------| :-----|  :----------|
| **ML to Automatically Detect Negative Reviews.**    | The Film Junky Union, a new edgy community for classic movie enthusiasts, is developing a system for filtering and categorizing movie reviews. The purpose of this project was to train a model to automatically detect negative reviews. For our exploratory data analysis and training/validation/testing components of the project, we used a dataset of IMBD movie reviews with polarity labelling to build a model for classifying positive and negative reviews. The goal of this project was to reach an F1 score of at least 0.85. | numpy, pandas, matplotlib, matplotlib.pyplot, seaborn, tqdm, re, sklearn.metrics, DummyClassifier, nltk, TfidfVectorizer, LogisticRegression, nltk.corpus.stopwords, nltk.tokenize.word_tokenize, nltk.stem.WordNetLemmatizer, spacy, LGBMClassifier, GridSearchCV, RandomizedSearchCV, torch, transformers.BERT |[Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/detecting_negative_reviews_project)|
| **Determining age of customers**   | The supermarket chain Good Seed would like to explore whether Data Science can help them adhere to alcohol laws by making sure they do not sell alcohol to people underage. The purpose of this project was to build and evaluate a model for verifying people's age For this project, we were provided with photographs of people with their ages indicated. | pandas, tensorflow.keras.preprocessing.image.ImageDataGenerator, matplotlib.pyplot, seaborn, PIL.Image, tensorflow, ResNet50, tensorflow.keras.models.Sequential, tensorflow.keras.layers.GlobalAveragePooling2D, tensorflow.keras.layers(Dense, Dropout, Flatten), tensorflow.keras.optimizers.Adam, inspect | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/determining_age_of_customers_project) |
| **Determining Price of Vehicles with Machine Learning**    | Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. For this project, we built a maching learning model with use of numerical method techniques to determine the value of vehicles. In this project, we trained different models with various hyperparameters (some models had various implementations of gradient boosting.) The main point of this step was to compare gradient boosting methods with random forest, decision tree, and linear regression.| pandas, numpy, matplotlib.pyplot, sklearn.preprocessing.OrdinalEncoder, sklearn.preprocessing.StandardScaler, LGBMRegressor, sklearn.model_selection.GridSearchCV,, sklearn.model_selection.RandomizedSearchCV, sklearn.metrics, datetime, RandomForestRegressor, DecisionTreeRegressor, sklearn.metrics.make_scorer, lightgbm, CatBoostRegressor, XGBRegressor, LinearRegression |[Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/determining_price_of_vehicles_project)|
| **Finding Similar Customers for Insurance Benefits**    | The Sure Tomorrow insurance company wanted to solve several tasks with the help of Machine Learning and use principles of linear algebra. The purpose of this project was to to evaluate that possibility, and solve the following tasks: Task 1: Find customers who are similar to a given customer by creating a K nearest neighbors algorithm and test with difference distances (Manhattan, Euclidean). This will help the company's agents with marketing. Task 2: Predict whether a new customer is likely to receive an insurance benefit. Determine if a prediction model can do better than a dummy model. Task 3: Predict the number of insurance benefits a new customer is likely to receive using a linear regression model. Task 4: Protect clients' personal data without breaking the model from the previous task by encrypting their data.| Data encrypting, Linear Algebra, numpy, pandas, seaborn, sklearn.linear_model, sklearn.metric, KNeighborsClassifier, sklearn.preprocessing, matplotlib.pyplot|  [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/finding_similar_customers_for_insurance_benefits_project)|
| **Forecasting Churn of Clients for Interconnect Company.**    | The purpose of this project was to create a Machine Learning model that predicts which costumers are at 'risk' of leaving the telecommunications company. The datasets provided from Interconnect include the costumers's personal information; information about their costumer's contracts; and information about costumers' phone and internet plans. For the rest of the project, we created machine learning models and selected the best model, with the highest AUC-ROC score. The threshold for the selected model was an AUC-ROC score was 0.85, and also our baseline was a logistic regression model. |pandas, numpy, matplotlib.pyplot, seaborn, LogisticRegression, RandomizedSearchCV, GridSearchCV, sklearn.metrics, sklearn.utils.shuffle, RandomForestClassifier, StandardScaler, OrdinalEncoder, CatBoostClassifier, KNeighborsClassifier | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/forecasting_churn_of_customers_for_telecommunications_company_project)|
| **Machine Learning Model to Find Best Location For Building a Well**    | In this project, we created a Linear Regression Machine Learning Model for the OilyGiant company. The company provided us with oil samples from 3 different regions, in which the parameters of each oil well in the region are already known. The purpose of this mahcine learning model was to pick the region with the highest profit margin. Similarly, we analyzed the potential profit and risks using the Boostrapping technique. | Boostrapping, pandas, numpy, sklearn.model_selection, LinearRegression, sklearn.metrics (f1_score, roc_curve, accuracy_score, roc_auc_score, mean_squared_error, r2_score), matplotlib.pyplot, scipy.stats | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/locating_region_to_build_wells_project)|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|


