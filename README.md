# Practicum Projects

## About
#### This repostitory containts 15 different projects focused on data storytelling, statistical analysis, data parsing, and machine learning, for the Data Science Professional Training Certificate Program by Practicum. 

## Table of Contents:

###  Machine Learning/Computer Vision/ Natural Language Processing Projects:

| **Name of Project**  | **Description of Project**  | **Tools/concepts used** | **Link to Project** | 
| :------------ |:---------------| :-----|  :----------|
| **ML to Automatically Detect Negative Reviews.**    | The Film Junky Union, a new edgy community for classic movie enthusiasts, is developing a system for filtering and categorizing movie reviews. The purpose of this project was to train a model to automatically detect negative reviews. For our exploratory data analysis and training/validation/testing components of the project, we used a dataset of IMBD movie reviews with polarity labelling to build a model for classifying positive and negative reviews. The goal of this project was to reach an F1 score of at least 0.85. | numpy, pandas, matplotlib, matplotlib.pyplot, seaborn, tqdm, re, sklearn.metrics, DummyClassifier, nltk, TfidfVectorizer, LogisticRegression, nltk.corpus.stopwords, nltk.tokenize.word_tokenize, nltk.stem.WordNetLemmatizer, spacy, LGBMClassifier, GridSearchCV, RandomizedSearchCV, torch, transformers.BERT |[Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/detecting_negative_reviews_project)|
| **Determining age of customers**   | The supermarket chain Good Seed would like to explore whether Data Science can help them adhere to alcohol laws by making sure they do not sell alcohol to people underage. The purpose of this project was to build and evaluate a model for verifying people's age For this project, we were provided with photographs of people with their ages indicated. | pandas, tensorflow.keras.preprocessing.image.ImageDataGenerator, matplotlib.pyplot, seaborn, PIL.Image, tensorflow, ResNet50, tensorflow.keras.models.Sequential, tensorflow.keras.layers.GlobalAveragePooling2D, tensorflow.keras.layers(Dense, Dropout, Flatten), tensorflow.keras.optimizers.Adam, inspect | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/determining_age_of_customers_project) |
| **Predicting Number of Taxi Orders**    | Sweet Lift is a taxi company that has collected historical data on taxi orders at airports. The purpose of this project is to attract more drivers during peak hours and predict the amount of taxi orders for the next hour by building a machine learning model for such a prediction. To create such machine learning model, we had to analyze the rolling mean and standard deviation of DateTime data with different window sizes to obtain smooth rolling and observe trends and seasonality in daily, and monthly periods. After analyzing and determining the window sizes that provided a smooth rolling for mean and standard deviation, we created lags of DateTime data as features to train and test Machine Learning modes including RandomForestRegressor, DecisionTreeRegressor, CatboostRegressor, and XGBRegressor models. The company’s RMSE threshold specifications were the folllwing: The RMSE metric on the test set should not be more than 48. | Time Series, pandas, numpy, statsmodels.tsa.seasonal.seasonal_decompose, matplotlib.pyplot, LinearRegression, sklearn.model_selection (train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score), sklearn.metrics(mean_squared_error, make_scorer), RandomForestRegressor, DecisionTreeRegressor, CatBoostRegressor, XGBRegressor, TimeSeriesSplit | [Link](https://github.com/jmorenoflores/practicum_projects/blob/main/machine_learning/predicting_taxi_orders_project/README.md)|
| **ML Model Predicting the Recovery of Gold**    | Zyfra, a company that develops efficiency solutions for heavy industry, needed a prototype of a machine learning model to predict the amount of gold recovered from gold ore. | pandas, numpy, datetime, seaborn, matplotlib.pyplot, scipy.stats, DecisionTreeClassifier, DecisionTreeRegressor, sklearn.model_selection (cross_val_score, KFold, GridSearchCV), LinearRegression, RandomForestRegressor, sklearn.metrics (mean_absolute_error, mean_squared_error, make_scorer), DummyRegressor | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/predicting_recovery_of_gold_project)|
| **Determining Price of Vehicles with Machine Learning**    | Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. For this project, we built a maching learning model with use of numerical method techniques to determine the value of vehicles. In this project, we trained different models with various hyperparameters (some models had various implementations of gradient boosting.) The main point of this step was to compare gradient boosting methods with random forest, decision tree, and linear regression.| pandas, numpy, matplotlib.pyplot, sklearn.preprocessing.OrdinalEncoder, sklearn.preprocessing.StandardScaler, LGBMRegressor, sklearn.model_selection.GridSearchCV,, sklearn.model_selection.RandomizedSearchCV, sklearn.metrics, datetime, RandomForestRegressor, DecisionTreeRegressor, sklearn.metrics.make_scorer, lightgbm, CatBoostRegressor, XGBRegressor, LinearRegression |[Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/determining_price_of_vehicles_project)|
| **Finding Similar Customers for Insurance Benefits**    | The Sure Tomorrow insurance company wanted to solve several tasks with the help of Machine Learning and use principles of linear algebra. The purpose of this project was to to evaluate that possibility, and solve the following tasks: Task 1: Find customers who are similar to a given customer by creating a K nearest neighbors algorithm and test with difference distances (Manhattan, Euclidean). This will help the company's agents with marketing. Task 2: Predict whether a new customer is likely to receive an insurance benefit. Determine if a prediction model can do better than a dummy model. Task 3: Predict the number of insurance benefits a new customer is likely to receive using a linear regression model. Task 4: Protect clients' personal data without breaking the model from the previous task by encrypting their data.| Data encrypting, Linear Algebra, numpy, pandas, seaborn, sklearn.linear_model, sklearn.metric, KNeighborsClassifier, sklearn.preprocessing, matplotlib.pyplot|  [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/finding_similar_customers_for_insurance_benefits_project)|
| **Forecasting Churn of Clients for Interconnect Company.**    | The purpose of this project was to create a Machine Learning model that predicts which costumers are at 'risk' of leaving the telecommunications company. The datasets provided from Interconnect include the costumers's personal information; information about their costumer's contracts; and information about costumers' phone and internet plans. For the rest of the project, we created machine learning models and selected the best model, with the highest AUC-ROC score. The threshold for the selected model was an AUC-ROC score was 0.85, and also our baseline was a logistic regression model. |pandas, numpy, matplotlib.pyplot, seaborn, LogisticRegression, RandomizedSearchCV, GridSearchCV, sklearn.metrics, sklearn.utils.shuffle, RandomForestClassifier, StandardScaler, OrdinalEncoder, CatBoostClassifier, KNeighborsClassifier | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/forecasting_churn_of_customers_for_telecommunications_company_project)|
| **Machine Learning Model to Find Best Location For Building a Well**    | In this project, we created a Linear Regression Machine Learning Model for the OilyGiant company. The company provided us with oil samples from 3 different regions, in which the parameters of each oil well in the region are already known. The purpose of this mahcine learning model was to pick the region with the highest profit margin. Similarly, we analyzed the potential profit and risks using the Boostrapping technique. | Boostrapping, pandas, numpy, sklearn.model_selection, LinearRegression, sklearn.metrics (f1_score, roc_curve, accuracy_score, roc_auc_score, mean_squared_error, r2_score), matplotlib.pyplot, scipy.stats | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/locating_region_to_build_wells_project)|
| **Will Costumers leave soon?**    | Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones. This project was used to create a machine learning model that predicts whether a customer will leave the bank soon based on the data of clients’ past behavior and termination of contracts with the bank. The project consisted of creating a DecissionTreeClassifier and a RandomForestClassifier model from the data; tuning each of the models' hyperparameters to obtain the highest F1 score, accuracy score, and AUC value from the ROC curve; The best model with the highest F1, accuracy, and AUC values was picked for the findings of task research. The threshold for the F1 score was a score of at least 0.59. | pandas, numpy, DecisionTreeClassifier, RandomForestClassifier, sklearn.model_selection, matplotlib.pyplot, OrdinalEncoder, StandardScaler, sklearn.metrics (f1_score, roc_curve, accuracy_score, roc_auc_score), sklearn.utils.shuffle, RandomizedSearchCV, GridSearchCV, linear_model | [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/predicting_if_customers_will_leave_bank_services_project)|
| **Machine Learning Model to Pick the Right Mobile Plan**    | Mobile carrier Megaline has found out that many of their subscribers use legacy plans. The purpose of this project was to develop a machine learning model that would analyze subscribers' behavior and recommend their customers one of Megaline's newer plans: Smart or Ultra. In this project, we analyzed the behavior data about subscribers who have already switched to the new plans. For this classification task, we developed a model that will pick the right plan and picked the model with the highest possible accuracy score. Megaline specified that the threshold for accuracy was 0.75. | pandas, DecisionTreeClassifier, RandomForestClassifier, sklearn.metrics (accuracy_score), sklearn.model_selection (train_test_split)| [Link](https://github.com/jmorenoflores/practicum_projects/tree/main/machine_learning/selecting_right_plan_project)|

### Exploratory and Statistical Analysis/ Data Parsing/ Tranforming data (PostgreSQL) Projects: 

| **Name of Project**  | **Description of Project**  | **Tools/concepts used** | **Link to Project** | 
| :------------ |:---------------| :-----|  :----------|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|
| ****    | @ | $1600 |   jsjsjs|


